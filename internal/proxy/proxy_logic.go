package proxy

import (
	"bytes"
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"regexp"
	"strconv"
	"strings"
	"time"

	"claude-code-codex-companion/internal/conversion"
	"claude-code-codex-companion/internal/endpoint"
	"claude-code-codex-companion/internal/tagging"
	"claude-code-codex-companion/internal/utils"

	"github.com/gin-gonic/gin"
)

func (s *Server) proxyToEndpoint(c *gin.Context, ep *endpoint.Endpoint, path string, requestBody []byte, requestID string, startTime time.Time, taggedRequest *tagging.TaggedRequest, attemptNumber int) (bool, bool) {
	// æ£€æŸ¥æ˜¯å¦ä¸º count_tokens è¯·æ±‚åˆ° OpenAI ç«¯ç‚¹
	isCountTokensRequest := strings.Contains(path, "/count_tokens")
	isOpenAIEndpoint := ep.EndpointType == "openai"

	// OpenAI ç«¯ç‚¹ä¸æ”¯æŒ count_tokensï¼Œç«‹å³å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
	if isCountTokensRequest && isOpenAIEndpoint {
		s.logger.Debug(fmt.Sprintf("Skipping count_tokens request on OpenAI endpoint %s", ep.Name))
		// æ ‡è®°è¿™æ¬¡å°è¯•ä¸ºç‰¹æ®Šæƒ…å†µï¼Œä¸è®°å½•å¥åº·ç»Ÿè®¡ï¼Œä¸è®°å½•æ—¥å¿—ï¼ˆé™¤éæ‰€æœ‰ç«¯ç‚¹éƒ½å› æ­¤å¤±è´¥ï¼‰
		c.Set("skip_health_record", true)
		c.Set("skip_logging", true)
		c.Set("count_tokens_openai_skip", true)
		c.Set("last_error", fmt.Errorf("count_tokens not supported on OpenAI endpoint"))
		c.Set("last_status_code", http.StatusNotFound)
		return false, true // ç«‹å³å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
	}
    // ä¸ºè¿™ä¸ªç«¯ç‚¹è®°å½•ç‹¬ç«‹çš„å¼€å§‹æ—¶é—´
    endpointStartTime := time.Now()
    // è®°å½•å…¥ç«™åŸå§‹è·¯å¾„ï¼Œä¸å®é™…è¯·æ±‚è·¯å¾„åŒºåˆ†
    inboundPath := path
    effectivePath := path
    targetURL := ep.GetFullURL(effectivePath)

	// Extract tags from taggedRequest
	var tags []string
	if taggedRequest != nil {
		tags = taggedRequest.Tags
	}

	// åˆ›å»ºHTTPè¯·æ±‚ç”¨äºæ¨¡å‹é‡å†™å¤„ç†
	tempReq, err := http.NewRequest(c.Request.Method, targetURL, bytes.NewReader(requestBody))
	if err != nil {
		s.logger.Error("Failed to create request", err)
		// è®°å½•åˆ›å»ºè¯·æ±‚å¤±è´¥çš„æ—¥å¿—
		duration := time.Since(endpointStartTime)
		createRequestError := fmt.Sprintf("Failed to create request: %v", err)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, requestBody, c, nil, nil, nil, duration, fmt.Errorf(createRequestError), false, tags, "", "", "", attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", fmt.Errorf(createRequestError))
		c.Set("last_status_code", 0)
		return false, false
	}

	// è·å–å®¢æˆ·ç«¯ç±»å‹
	var clientType string
	if detection, exists := c.Get("format_detection"); exists {
		if det, ok := detection.(*utils.FormatDetectionResult); ok {
			clientType = string(det.ClientType)
		}
	}

	// åº”ç”¨æ¨¡å‹é‡å†™ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
	originalModel, rewrittenModel, err := s.modelRewriter.RewriteRequestWithTags(tempReq, ep.ModelRewrite, ep.Tags, clientType)
	if err != nil {
		s.logger.Error("Model rewrite failed", err)
		// è®°å½•æ¨¡å‹é‡å†™å¤±è´¥çš„æ—¥å¿—
		duration := time.Since(endpointStartTime)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, requestBody, c, nil, nil, nil, duration, err, false, tags, "", "", "", attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", err)
		c.Set("last_status_code", 0)
		return false, false
	}

	// å¦‚æœè¿›è¡Œäº†æ¨¡å‹é‡å†™ï¼Œè·å–é‡å†™åçš„è¯·æ±‚ä½“
	var finalRequestBody []byte
	if originalModel != "" && rewrittenModel != "" {
		finalRequestBody, err = io.ReadAll(tempReq.Body)
		if err != nil {
			s.logger.Error("Failed to read rewritten request body", err)
			duration := time.Since(endpointStartTime)
			s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, nil, nil, nil, duration, err, false, tags, "", originalModel, rewrittenModel, attemptNumber)
			// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
			c.Set("last_error", err)
			c.Set("last_status_code", 0)
			return false, false
		}
	} else {
		finalRequestBody = requestBody // ä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
	}

	// æ ¼å¼è½¬æ¢ï¼ˆåœ¨æ¨¡å‹é‡å†™ä¹‹åï¼‰
	// å…³é”®ä¿®å¤ï¼šåªæœ‰å½“è¯·æ±‚æ ¼å¼ä¸ç«¯ç‚¹æ ¼å¼ä¸åŒ¹é…æ—¶æ‰éœ€è¦è½¬æ¢
	var conversionContext *conversion.ConversionContext
	var formatDetection *utils.FormatDetectionResult

	// ä» context è·å–æ ¼å¼æ£€æµ‹ç»“æœ
	if detection, exists := c.Get("format_detection"); exists {
		if det, ok := detection.(*utils.FormatDetectionResult); ok {
			formatDetection = det
		}
	}

	// åˆ¤æ–­æ˜¯å¦éœ€è¦æ ¼å¼è½¬æ¢
	needsConversion := false
	if formatDetection != nil && formatDetection.Format != utils.FormatUnknown {
		// æœ‰æ˜ç¡®çš„æ ¼å¼æ£€æµ‹ç»“æœ
		requestIsAnthropic := (formatDetection.Format == utils.FormatAnthropic)
		endpointIsOpenAI := (ep.EndpointType == "openai")

		// Anthropicæ ¼å¼è¯·æ±‚ + OpenAIç«¯ç‚¹ = éœ€è¦è½¬æ¢
		// OpenAIæ ¼å¼è¯·æ±‚ + OpenAIç«¯ç‚¹ = ä¸éœ€è¦è½¬æ¢ï¼ˆç›´æ¥é€ä¼ ï¼‰
		// Anthropicæ ¼å¼è¯·æ±‚ + Anthropicç«¯ç‚¹ = ä¸éœ€è¦è½¬æ¢ï¼ˆç›´æ¥é€ä¼ ï¼‰
		needsConversion = requestIsAnthropic && endpointIsOpenAI

		s.logger.Debug("Format conversion decision", map[string]interface{}{
			"request_format":    formatDetection.Format,
			"endpoint_type":     ep.EndpointType,
			"needs_conversion":  needsConversion,
			"detection_confidence": formatDetection.Confidence,
		})
	} else {
		// æ²¡æœ‰æ ¼å¼æ£€æµ‹ç»“æœï¼Œä½¿ç”¨æ—§é€»è¾‘ï¼ˆå‘åå…¼å®¹ï¼‰
		needsConversion = s.converter.ShouldConvert(ep.EndpointType)
	}

	if needsConversion {
		s.logger.Info(fmt.Sprintf("Starting request conversion for endpoint type: %s", ep.EndpointType))

		// åˆ›å»ºç«¯ç‚¹ä¿¡æ¯
		endpointInfo := &conversion.EndpointInfo{
			Type:               ep.EndpointType,
			MaxTokensFieldName: ep.MaxTokensFieldName,
		}

		convertedBody, ctx, err := s.converter.ConvertRequest(finalRequestBody, endpointInfo)
		if err != nil {
			s.logger.Error("Request format conversion failed", err)
			duration := time.Since(endpointStartTime)
			s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, nil, nil, nil, duration, err, false, tags, "", originalModel, rewrittenModel, attemptNumber)
			// Requestè½¬æ¢å¤±è´¥æ˜¯è¯·æ±‚æ ¼å¼é—®é¢˜ï¼Œä¸åº”è¯¥é‡è¯•å…¶ä»–ç«¯ç‚¹ï¼Œç›´æ¥è¿”å›é”™è¯¯
			c.JSON(http.StatusBadRequest, gin.H{"error": "Request format conversion failed", "details": err.Error()})
			// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
			c.Set("last_error", err)
			c.Set("last_status_code", http.StatusBadRequest)
			return false, false // ä¸é‡è¯•ï¼Œç›´æ¥è¿”å›
		}
		finalRequestBody = convertedBody
		conversionContext = ctx
		s.logger.Debug("Request format converted successfully", map[string]interface{}{
			"endpoint_type":  ep.EndpointType,
			"original_size":  len(requestBody),
			"converted_size": len(convertedBody),
		})
	} else {
		s.logger.Debug("Skipping format conversion (not needed)", map[string]interface{}{
			"request_format": func() string {
				if formatDetection != nil {
					return string(formatDetection.Format)
				}
				return "unknown"
			}(),
			"endpoint_type": ep.EndpointType,
		})
	}

	// Codex /responses æ ¼å¼è½¬æ¢ä¸º OpenAI /chat/completions æ ¼å¼
	// è‡ªåŠ¨æ¢æµ‹é€»è¾‘ï¼š
	// - NativeCodexFormat == nil: æœªæ¢æµ‹ï¼Œé¦–æ¬¡è¯·æ±‚ä½¿ç”¨åŸç”Ÿæ ¼å¼ï¼Œæ”¶åˆ°400åè‡ªåŠ¨é‡è¯•
	// - NativeCodexFormat == true: ç«¯ç‚¹æ”¯æŒåŸç”Ÿ Codex æ ¼å¼ï¼Œè·³è¿‡è½¬æ¢
	// - NativeCodexFormat == false: ç«¯ç‚¹éœ€è¦ OpenAI æ ¼å¼ï¼Œæ‰§è¡Œè½¬æ¢
	
	codexNeedsConversion := false
    if ep.EndpointType == "openai" && inboundPath == "/responses" {
		if ep.NativeCodexFormat == nil {
			// é¦–æ¬¡è¯·æ±‚ï¼Œä½¿ç”¨åŸç”Ÿæ ¼å¼å°è¯•ï¼ˆæ”¶åˆ°400åä¼šè‡ªåŠ¨è½¬æ¢å¹¶é‡è¯•ï¼‰
			s.logger.Info("First /responses request to endpoint, trying native Codex format", map[string]interface{}{
				"endpoint": ep.Name,
			})
			codexNeedsConversion = false
		} else if *ep.NativeCodexFormat {
			// å·²æ¢æµ‹ï¼šæ”¯æŒåŸç”Ÿ Codex æ ¼å¼
			s.logger.Debug("Using native Codex format (previously detected)", map[string]interface{}{
				"endpoint": ep.Name,
			})
			codexNeedsConversion = false
		} else {
			// å·²æ¢æµ‹ï¼šéœ€è¦è½¬æ¢ä¸º OpenAI æ ¼å¼
			s.logger.Debug("Converting to OpenAI format (previously detected)", map[string]interface{}{
				"endpoint": ep.Name,
			})
			codexNeedsConversion = true
		}
	}
	
    	if codexNeedsConversion {
        	// å°† Codex æ ¼å¼è½¬æ¢ä¸º OpenAI Chat Completionsï¼Œå¹¶åˆ‡æ¢è·¯å¾„åˆ° /chat/completions
        	// å¤§å¤šæ•° OpenAI å…¼å®¹ç«¯ç‚¹ï¼ˆåŒ…æ‹¬ 88codeï¼‰ä¸æ”¯æŒ /responses
        	if inboundPath == "/responses" {
        		effectivePath = "/chat/completions"
        		targetURL = ep.GetFullURL(effectivePath)
        	}
        	convertedBody, err := s.convertCodexToOpenAI(finalRequestBody)
		if err != nil {
			s.logger.Debug("Failed to convert Codex format to OpenAI", map[string]interface{}{
				"error": err.Error(),
			})
			// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
		} else if convertedBody != nil {
			finalRequestBody = convertedBody
                s.logger.Info("Codex format converted to OpenAI format", map[string]interface{}{
                    "path": effectivePath,
                })

			// è°ƒè¯•ï¼šè¾“å‡ºè½¬æ¢åçš„è¯·æ±‚ä½“ï¼ˆæˆªæ–­åˆ°å‰500å­—ç¬¦ï¼‰
			bodyPreview := string(convertedBody)
			if len(bodyPreview) > 500 {
				bodyPreview = bodyPreview[:500] + "..."
			}
			s.logger.Debug("Converted Codex request body", map[string]interface{}{
				"body": bodyPreview,
			})
		}
	}

	// OpenAI user å‚æ•°é•¿åº¦é™åˆ¶ hackï¼ˆåœ¨æ ¼å¼è½¬æ¢ä¹‹åï¼Œå‚æ•°è¦†ç›–ä¹‹å‰ï¼‰
	if ep.EndpointType == "openai" {
		hackedBody, err := s.applyOpenAIUserLengthHack(finalRequestBody)
		if err != nil {
			s.logger.Debug("Failed to apply OpenAI user length hack", map[string]interface{}{
				"error": err.Error(),
			})
			// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
		} else if hackedBody != nil {
			finalRequestBody = hackedBody
			s.logger.Debug("OpenAI user parameter length hack applied")
		}

		// GPT-5 æ¨¡å‹ç‰¹æ®Šå¤„ç† hack
		// åªæœ‰å½“æœ€ç»ˆæ¨¡å‹ï¼ˆé‡å†™åï¼‰ä»ç„¶æ˜¯ GPT-5 æ—¶æ‰åº”ç”¨ hack
		// å¦‚æœæ¨¡å‹è¢«é‡å†™æˆå…¶ä»–æ¨¡å‹ï¼ˆå¦‚ qwen3-coderï¼‰ï¼Œåˆ™è·³è¿‡ hack
		finalModel := rewrittenModel
		if finalModel == "" {
			finalModel = originalModel
		}
		shouldApplyGPT5Hack := finalModel == "" || strings.Contains(strings.ToLower(finalModel), "gpt-5")

		if shouldApplyGPT5Hack {
			gpt5HackedBody, err := s.applyGPT5ModelHack(finalRequestBody)
			if err != nil {
				s.logger.Debug("Failed to apply GPT-5 model hack", map[string]interface{}{
					"error": err.Error(),
				})
				// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
			} else if gpt5HackedBody != nil {
				finalRequestBody = gpt5HackedBody
				s.logger.Debug("GPT-5 model hack applied")
			}
		} else {
			s.logger.Debug("Skipping GPT-5 hack (model was rewritten)", map[string]interface{}{
				"original_model": originalModel,
				"final_model":    finalModel,
			})
		}
	}

	// è‡ªåŠ¨ç§»é™¤ä¸æ”¯æŒçš„å‚æ•°ï¼ˆåŸºäºæ¨¡å‹åç§°æ™ºèƒ½æ£€æµ‹ï¼‰
	// è‡ªåŠ¨ç§»é™¤è¯¥ç«¯ç‚¹å·²å­¦ä¹ åˆ°çš„ä¸æ”¯æŒå‚æ•°
	if cleanedBody, wasModified := s.autoRemoveUnsupportedParams(finalRequestBody, ep); wasModified {
		finalRequestBody = cleanedBody
		modelForCheck := rewrittenModel
		if modelForCheck == "" {
			modelForCheck = originalModel
		}
		s.logger.Info("Auto-removed unsupported parameters based on endpoint learning", map[string]interface{}{
			"model":    modelForCheck,
			"endpoint": ep.Name,
		})
	}

	// åº”ç”¨è¯·æ±‚å‚æ•°è¦†ç›–è§„åˆ™ï¼ˆåœ¨æ ¼å¼è½¬æ¢ä¹‹åï¼Œåˆ›å»ºHTTPè¯·æ±‚ä¹‹å‰ï¼‰
	if parameterOverrides := ep.GetParameterOverrides(); parameterOverrides != nil && len(parameterOverrides) > 0 {
		overriddenBody, err := s.applyParameterOverrides(finalRequestBody, parameterOverrides)
		if err != nil {
			s.logger.Debug("Failed to apply parameter overrides", map[string]interface{}{
				"error": err.Error(),
			})
			// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
		} else {
			finalRequestBody = overriddenBody
			s.logger.Info("Request parameter overrides applied", map[string]interface{}{
				"endpoint":        ep.Name,
				"overrides_count": len(parameterOverrides),
			})
		}
	}

	// åˆ›å»ºæœ€ç»ˆçš„HTTPè¯·æ±‚
	req, err := http.NewRequest(c.Request.Method, targetURL, bytes.NewReader(finalRequestBody))
	if err != nil {
		s.logger.Error("Failed to create final request", err)
		// è®°å½•åˆ›å»ºè¯·æ±‚å¤±è´¥çš„æ—¥å¿—
		duration := time.Since(endpointStartTime)
		createRequestError := fmt.Sprintf("Failed to create final request: %v", err)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, nil, nil, nil, duration, fmt.Errorf(createRequestError), false, tags, "", originalModel, rewrittenModel, attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", fmt.Errorf(createRequestError))
		c.Set("last_status_code", 0)
		return false, false
	}

	for key, values := range c.Request.Header {
		if key == "Authorization" {
			continue
		}
		for _, value := range values {
			req.Header.Add(key, value)
		}
	}

	// æ ¹æ®è®¤è¯ç±»å‹è®¾ç½®ä¸åŒçš„è®¤è¯å¤´éƒ¨
	if ep.AuthType == "api_key" {
		req.Header.Set("x-api-key", ep.AuthValue)
	} else {
		authHeader, err := ep.GetAuthHeaderWithRefreshCallback(s.config.Timeouts.ToProxyTimeoutConfig(), s.createOAuthTokenRefreshCallback())
		if err != nil {
			s.logger.Error(fmt.Sprintf("Failed to get auth header: %v", err), err)
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Authentication failed"})
			// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
			c.Set("last_error", err)
			c.Set("last_status_code", http.StatusUnauthorized)
			return false, false
		}
		req.Header.Set("Authorization", authHeader)
	}

	// Special OAuth header hack for api.anthropic.com with OAuth tokens
	if strings.Contains(ep.URL, "api.anthropic.com") && ep.AuthType == "auth_token" && strings.HasPrefix(ep.AuthValue, "sk-ant-oat01") {
		if existingBeta := req.Header.Get("Anthropic-Beta"); existingBeta != "" {
			// Prepend oauth-2025-04-20 to existing Anthropic-Beta header
			req.Header.Set("Anthropic-Beta", "oauth-2025-04-20,"+existingBeta)
		} else {
			// Set oauth-2025-04-20 as the only value if no existing header
			req.Header.Set("Anthropic-Beta", "oauth-2025-04-20")
		}
	}

	// åº”ç”¨HTTP Headerè¦†ç›–è§„åˆ™ï¼ˆåœ¨æ‰€æœ‰å…¶ä»–headerå¤„ç†ä¹‹åï¼‰
	if headerOverrides := ep.GetHeaderOverrides(); headerOverrides != nil && len(headerOverrides) > 0 {
		for headerName, headerValue := range headerOverrides {
			if headerValue == "" {
				// ç©ºå€¼è¡¨ç¤ºåˆ é™¤header
				req.Header.Del(headerName)
				s.logger.Debug(fmt.Sprintf("Header override: deleted header %s for endpoint %s", headerName, ep.Name))
			} else {
				// éç©ºå€¼è¡¨ç¤ºè®¾ç½®header
				req.Header.Set(headerName, headerValue)
				s.logger.Debug(fmt.Sprintf("Header override: set header %s = [REDACTED] for endpoint %s", headerName, ep.Name))
			}
		}
	}

	if c.Request.URL.RawQuery != "" {
		req.URL.RawQuery = c.Request.URL.RawQuery
	}

	// ä¸ºè¿™ä¸ªç«¯ç‚¹åˆ›å»ºæ”¯æŒä»£ç†çš„HTTPå®¢æˆ·ç«¯
	client, err := ep.CreateProxyClient(s.config.Timeouts.ToProxyTimeoutConfig())
	if err != nil {
		s.logger.Error("Failed to create proxy client for endpoint", err)
		duration := time.Since(endpointStartTime)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, nil, nil, duration, err, s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", err)
		c.Set("last_status_code", 0)
		return false, true
	}

        resp, err := client.Do(req)
        if err != nil {
            // å¦‚æœæ˜¯é¦–æ¬¡å¯¹ OpenAI ç«¯ç‚¹çš„ /responses è¯·æ±‚å‘ç”Ÿç½‘ç»œçº§é”™è¯¯ï¼ˆå¦‚ EOFï¼‰ï¼Œè§†ä½œä¸æ”¯æŒ responsesï¼Œè½¬æ¢å¹¶æ”¹ç”¨ /chat/completions é‡è¯•
            if ep.EndpointType == "openai" && inboundPath == "/responses" && ep.NativeCodexFormat == nil {
                s.logger.Info("Network error on first /responses request - converting to OpenAI format and retrying /chat/completions", map[string]interface{}{
                    "endpoint": ep.Name,
                    "error":    err.Error(),
                })
                falseValue := false
                ep.NativeCodexFormat = &falseValue
                if convertedBody, convertErr := s.convertCodexToOpenAI(requestBody); convertErr == nil && convertedBody != nil {
                    // é€’å½’é‡è¯•åˆ° /chat/completions
                    return s.proxyToEndpoint(c, ep, "/chat/completions", convertedBody, requestID, startTime, taggedRequest, attemptNumber)
                }
                // è½¬æ¢å¤±è´¥åˆ™ç»§ç»­æŒ‰åŸé€»è¾‘è®°å½•å¹¶äº¤ç»™ä¸Šå±‚é‡è¯•å…¶ä»–ç«¯ç‚¹
            }

            duration := time.Since(endpointStartTime)
            s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, nil, nil, duration, err, s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
            // è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­ï¼Œä¾›é‡è¯•é€»è¾‘ä½¿ç”¨
            c.Set("last_error", err)
            c.Set("last_status_code", 0) // ç½‘ç»œé”™è¯¯ï¼Œæ²¡æœ‰çŠ¶æ€ç 
            return false, true
        }
	defer resp.Body.Close()

	// æ£€æŸ¥è®¤è¯å¤±è´¥æƒ…å†µï¼Œå¦‚æœæ˜¯OAuthç«¯ç‚¹ä¸”æœ‰refresh_tokenï¼Œå…ˆå°è¯•åˆ·æ–°token
	if (resp.StatusCode == 401 || resp.StatusCode == 403) &&
		ep.AuthType == "oauth" &&
		ep.OAuthConfig != nil &&
		ep.OAuthConfig.RefreshToken != "" {

		// æ£€æŸ¥æ˜¯å¦å·²ç»å› ä¸ºè¿™ä¸ªç«¯ç‚¹çš„è®¤è¯é—®é¢˜åˆ·æ–°è¿‡token
		refreshKey := fmt.Sprintf("oauth_refresh_attempted_%s", ep.ID)
		if _, alreadyRefreshed := c.Get(refreshKey); !alreadyRefreshed {
			s.logger.Info(fmt.Sprintf("Authentication failed (HTTP %d) for OAuth endpoint %s, attempting token refresh", resp.StatusCode, ep.Name))

			// æ ‡è®°æˆ‘ä»¬å·²ç»ä¸ºè¿™ä¸ªç«¯ç‚¹å°è¯•è¿‡tokenåˆ·æ–°ï¼Œé¿å…æ— é™å¾ªç¯
			c.Set(refreshKey, true)

			// å°è¯•åˆ·æ–°token
			if refreshErr := ep.RefreshOAuthTokenWithCallback(s.config.Timeouts.ToProxyTimeoutConfig(), s.createOAuthTokenRefreshCallback()); refreshErr != nil {
				s.logger.Error(fmt.Sprintf("Failed to refresh OAuth token for endpoint %s: %v", ep.Name, refreshErr), refreshErr)

				// åˆ·æ–°å¤±è´¥ï¼Œè¯»å–å“åº”ä½“ç”¨äºæ—¥å¿—è®°å½•
				duration := time.Since(endpointStartTime)
				body, _ := io.ReadAll(resp.Body)
				contentEncoding := resp.Header.Get("Content-Encoding")
				decompressedBody, err := s.validator.GetDecompressedBody(body, contentEncoding)
				if err != nil {
					decompressedBody = body // å¦‚æœè§£å‹å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
				}

				s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, decompressedBody, duration, nil, s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
				// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
				c.Set("last_error", fmt.Errorf("OAuth token refresh failed: %v", refreshErr))
				c.Set("last_status_code", resp.StatusCode)
				return false, true
			} else {
				s.logger.Info(fmt.Sprintf("OAuth token refreshed successfully for endpoint %s, retrying request", ep.Name))

				// å…³é—­åŸå§‹å“åº”ä½“
				resp.Body.Close()

				// Tokenåˆ·æ–°æˆåŠŸï¼Œé€’å½’é‡è¯•ç›¸åŒçš„endpointï¼ˆé‡æ–°èµ°å®Œæ•´çš„è¯·æ±‚æµç¨‹ï¼‰
				return s.proxyToEndpoint(c, ep, path, requestBody, requestID, startTime, taggedRequest, attemptNumber)
			}
		} else {
			s.logger.Debug(fmt.Sprintf("OAuth token refresh already attempted for endpoint %s in this request, not retrying", ep.Name))
		}
	}

	// åªæœ‰2xxçŠ¶æ€ç æ‰è®¤ä¸ºæ˜¯æˆåŠŸï¼Œå…¶ä»–æ‰€æœ‰çŠ¶æ€ç éƒ½å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
	if resp.StatusCode < 200 || resp.StatusCode >= 300 {
		duration := time.Since(endpointStartTime)
		body, _ := io.ReadAll(resp.Body)

		// è§£å‹å“åº”ä½“ç”¨äºæ—¥å¿—è®°å½•
		contentEncoding := resp.Header.Get("Content-Encoding")
		decompressedBody, err := s.validator.GetDecompressedBody(body, contentEncoding)
		if err != nil {
			decompressedBody = body // å¦‚æœè§£å‹å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
		}

		// ğŸ“ è‡ªåŠ¨å­¦ä¹ ä¸æ”¯æŒçš„å‚æ•° - åŸºäº400é”™è¯¯åˆ†æå¹¶é‡è¯•
		if resp.StatusCode == 400 {
			// è®°å½•å­¦ä¹ å‰çš„å‚æ•°åˆ—è¡¨é•¿åº¦
			paramCountBefore := len(ep.GetLearnedUnsupportedParams())

			// å°è¯•ä»é”™è¯¯ä¸­å­¦ä¹ ä¸æ”¯æŒçš„å‚æ•°
			s.learnUnsupportedParamsFromError(decompressedBody, ep, finalRequestBody)

			// å¦‚æœå­¦ä¹ åˆ°äº†æ–°å‚æ•°ï¼Œç§»é™¤å®ƒä»¬å¹¶ç«‹å³é‡è¯•
			paramCountAfter := len(ep.GetLearnedUnsupportedParams())
			if paramCountAfter > paramCountBefore {
				s.logger.Info("Learned new unsupported parameters, retrying with clean request", map[string]interface{}{
					"endpoint": ep.Name,
					"learned_count": paramCountAfter - paramCountBefore,
				})

				// ç§»é™¤å·²å­¦ä¹ çš„ä¸æ”¯æŒå‚æ•°
				cleanedBody, wasModified := s.autoRemoveUnsupportedParams(finalRequestBody, ep)
				if wasModified {
					// ä½¿ç”¨æ¸…ç†åçš„è¯·æ±‚ä½“é€’å½’é‡è¯•å½“å‰ç«¯ç‚¹
					s.logger.Debug("Retrying request after removing learned unsupported parameters")
					return s.proxyToEndpoint(c, ep, path, cleanedBody, requestID, startTime, taggedRequest, attemptNumber)
				}
			}
		}

            // ğŸ” è‡ªåŠ¨æ¢æµ‹ Codex æ ¼å¼æ”¯æŒ
            // å¦‚æœæ˜¯é¦–ä¸ª /responses è¯·æ±‚ä¸”è¿”å› 4xx/5xxï¼ˆæ’é™¤ 401/403 è®¤è¯ç±»ï¼‰ï¼Œ
            // è§†ä¸ºç«¯ç‚¹ä¸æ”¯æŒåŸç”Ÿ Codex /responsesï¼šè½¬æ¢ä¸º OpenAI æ ¼å¼å¹¶æ”¹èµ° /chat/completions é‡è¯•
            if (resp.StatusCode >= 400 && resp.StatusCode < 600 && resp.StatusCode != 401 && resp.StatusCode != 403) &&
               ep.EndpointType == "openai" &&
               inboundPath == "/responses" &&
               ep.NativeCodexFormat == nil {
			
			s.logger.Info("Received 400 on first /responses request - endpoint requires OpenAI format", map[string]interface{}{
				"endpoint": ep.Name,
			})
			
			// æ ‡è®°è¯¥ç«¯ç‚¹ä¸æ”¯æŒåŸç”Ÿ Codex æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
			falseValue := false
			ep.NativeCodexFormat = &falseValue
			
			// è½¬æ¢ Codex æ ¼å¼åˆ° OpenAI æ ¼å¼
			convertedBody, convertErr := s.convertCodexToOpenAI(requestBody)
			if convertErr != nil {
				s.logger.Error("Failed to convert Codex format to OpenAI for retry", convertErr)
				// è½¬æ¢å¤±è´¥ï¼Œè®°å½•æ—¥å¿—å¹¶å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
				s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, decompressedBody, duration, nil, s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
				c.Set("last_error", fmt.Errorf("format conversion failed: %v", convertErr))
				c.Set("last_status_code", resp.StatusCode)
				return false, true
			}
			
			s.logger.Info("Auto-converted to OpenAI format, retrying request", map[string]interface{}{
				"endpoint": ep.Name,
			})
			
			// å…³é—­åŸå“åº”
			resp.Body.Close()
			
                // ç”¨è½¬æ¢åçš„è¯·æ±‚ä½“é‡è¯•ï¼ˆé€’å½’è°ƒç”¨ï¼Œä¼šä½¿ç”¨æ–°çš„ NativeCodexFormat é…ç½®ï¼‰
                // åŒæ—¶åˆ‡æ¢åˆ° /chat/completions è·¯å¾„
                return s.proxyToEndpoint(c, ep, "/chat/completions", convertedBody, requestID, startTime, taggedRequest, attemptNumber)
		}

		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, decompressedBody, duration, nil, s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
		s.logger.Debug(fmt.Sprintf("HTTP error %d from endpoint %s, trying next endpoint", resp.StatusCode, ep.Name))
		// è®¾ç½®çŠ¶æ€ç åˆ°contextä¸­ï¼Œä¾›é‡è¯•é€»è¾‘ä½¿ç”¨
		c.Set("last_error", nil)
		c.Set("last_status_code", resp.StatusCode)
		return false, true
	}

	responseBody, err := io.ReadAll(resp.Body)
	if err != nil {
		s.logger.Error("Failed to read response body", err)
		// è®°å½•è¯»å–å“åº”ä½“å¤±è´¥çš„æ—¥å¿—
		duration := time.Since(endpointStartTime)
		readError := fmt.Sprintf("Failed to read response body: %v", err)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, nil, duration, fmt.Errorf(readError), s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", fmt.Errorf(readError))
		c.Set("last_status_code", resp.StatusCode)
		return false, false
	}

	// è§£å‹å“åº”ä½“ä»…ç”¨äºæ—¥å¿—è®°å½•å’ŒéªŒè¯
	contentEncoding := resp.Header.Get("Content-Encoding")
	decompressedBody, err := s.validator.GetDecompressedBody(responseBody, contentEncoding)
	if err != nil {
		s.logger.Error("Failed to decompress response body", err)
		// è®°å½•è§£å‹å“åº”ä½“å¤±è´¥çš„æ—¥å¿—
		duration := time.Since(endpointStartTime)
		decompressError := fmt.Sprintf("Failed to decompress response body: %v", err)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, responseBody, duration, fmt.Errorf(decompressError), s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", fmt.Errorf(decompressError))
		c.Set("last_status_code", resp.StatusCode)
		return false, false
	}

	// æ™ºèƒ½æ£€æµ‹å†…å®¹ç±»å‹å¹¶è‡ªåŠ¨è¦†ç›–
	currentContentType := resp.Header.Get("Content-Type")
	newContentType, overrideInfo := s.validator.SmartDetectContentType(decompressedBody, currentContentType, resp.StatusCode)

	// ç¡®å®šæœ€ç»ˆçš„Content-Typeå’Œæ˜¯å¦ä¸ºæµå¼å“åº”
	finalContentType := currentContentType
	if newContentType != "" {
		finalContentType = newContentType
		s.logger.Info(fmt.Sprintf("Auto-detected content type mismatch for endpoint %s: %s", ep.Name, overrideInfo))
	}

	// åˆ¤æ–­æ˜¯å¦ä¸ºæµå¼å“åº”ï¼ˆåŸºäºæœ€ç»ˆçš„Content-Typeï¼‰
	isStreaming := strings.Contains(strings.ToLower(finalContentType), "text/event-stream")

	// æ·»åŠ è°ƒè¯•æ—¥å¿—
	if len(decompressedBody) > 0 && len(decompressedBody) < 500 {
		s.logger.Debug(fmt.Sprintf("Response from %s - ContentType: %s, IsStreaming: %v, BodyPreview: %s",
			ep.Name, finalContentType, isStreaming, string(decompressedBody)))
	} else if len(decompressedBody) > 0 {
		s.logger.Debug(fmt.Sprintf("Response from %s - ContentType: %s, IsStreaming: %v, BodySize: %d, BodyPreview: %s...",
			ep.Name, finalContentType, isStreaming, len(decompressedBody), string(decompressedBody[:200])))
	}

	// å¤åˆ¶å“åº”å¤´ï¼Œä½†è·³è¿‡å¯èƒ½éœ€è¦é‡æ–°è®¡ç®—çš„å¤´éƒ¨
	for key, values := range resp.Header {
		keyLower := strings.ToLower(key)
		if keyLower == "content-type" && newContentType != "" {
			c.Header(key, finalContentType)
		} else if keyLower == "content-length" || keyLower == "content-encoding" {
			// è¿™äº›å¤´éƒ¨ä¼šåœ¨åé¢æ ¹æ®æœ€ç»ˆå“åº”ä½“é‡æ–°è®¾ç½®
			continue
		} else {
			for _, value := range values {
				c.Header(key, value)
			}
		}
	}

	// ç›‘æ§Anthropic rate limit headers
	if ep.ShouldMonitorRateLimit() {
		if err := s.processRateLimitHeaders(ep, resp.Header, requestID); err != nil {
			s.logger.Error("Failed to process rate limit headers", err)
		}
	}

	// ä¸¥æ ¼ Anthropic æ ¼å¼éªŒè¯å·²æ°¸ä¹…å¯ç”¨
	if err := s.validator.ValidateResponseWithPath(decompressedBody, isStreaming, ep.EndpointType, path, ep.URL); err != nil {
		// å¦‚æœæ˜¯usageç»Ÿè®¡éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªendpoint
		if strings.Contains(err.Error(), "invalid usage stats") {
			s.logger.Info(fmt.Sprintf("Usage validation failed for endpoint %s: %v", ep.Name, err))
			duration := time.Since(endpointStartTime)
			errorLog := fmt.Sprintf("Usage validation failed: %v", err)
			s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, append(decompressedBody, []byte(errorLog)...), duration, fmt.Errorf(errorLog), s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
			// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
			c.Set("last_error", fmt.Errorf(errorLog))
			c.Set("last_status_code", resp.StatusCode)
			return false, true // éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªendpoint
		}

		// å¦‚æœæ˜¯SSEæµä¸å®Œæ•´çš„éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªendpoint
		if strings.Contains(err.Error(), "incomplete SSE stream") || strings.Contains(err.Error(), "missing message_stop") || strings.Contains(err.Error(), "missing [DONE]") || strings.Contains(err.Error(), "missing finish_reason") {
			s.logger.Info(fmt.Sprintf("Incomplete SSE stream detected for endpoint %s: %v", ep.Name, err))
			duration := time.Since(endpointStartTime)
			errorLog := fmt.Sprintf("SSE validation failed: %v", err)
			s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, append(decompressedBody, []byte(errorLog)...), duration, fmt.Errorf(errorLog), s.isRequestExpectingStream(req), tags, "", originalModel, rewrittenModel, attemptNumber)
			// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
			c.Set("last_error", fmt.Errorf(errorLog))
			c.Set("last_status_code", resp.StatusCode)
			return false, true // éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªendpoint
		}
			
		// éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
		s.logger.Info(fmt.Sprintf("Response validation failed for endpoint %s, trying next endpoint: %v", ep.Name, err))
		duration := time.Since(endpointStartTime)
		validationError := fmt.Sprintf("Response validation failed: %v", err)
		s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, decompressedBody, duration, fmt.Errorf(validationError), isStreaming, tags, "", originalModel, rewrittenModel, attemptNumber)
		// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
		c.Set("last_error", fmt.Errorf(validationError))
		c.Set("last_status_code", resp.StatusCode)
		return false, true // éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªendpoint
	}

	c.Status(resp.StatusCode)

	// æ ¼å¼è½¬æ¢ï¼ˆåœ¨æ¨¡å‹é‡å†™ä¹‹å‰ï¼‰
	convertedResponseBody := decompressedBody
	if conversionContext != nil {
		s.logger.Info(fmt.Sprintf("Starting response conversion. Streaming: %v, OriginalSize: %d", isStreaming, len(decompressedBody)))
		convertedResp, err := s.converter.ConvertResponse(decompressedBody, conversionContext, isStreaming)
		if err != nil {
			s.logger.Error("Response format conversion failed", err)
			// Responseè½¬æ¢å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶å°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
			duration := time.Since(endpointStartTime)
			conversionError := fmt.Sprintf("Response format conversion failed: %v", err)
			s.logSimpleRequest(requestID, ep.URL, c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, decompressedBody, duration, fmt.Errorf(conversionError), isStreaming, tags, "", originalModel, rewrittenModel, attemptNumber)
			// è®¾ç½®é”™è¯¯ä¿¡æ¯åˆ°contextä¸­
			c.Set("last_error", fmt.Errorf(conversionError))
			c.Set("last_status_code", resp.StatusCode)
			return false, true // Responseè½¬æ¢å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
		} else {
			convertedResponseBody = convertedResp
			s.logger.Info(fmt.Sprintf("Response conversion successful! Original: %d bytes -> Converted: %d bytes", len(decompressedBody), len(convertedResp)))
			s.logger.Debug("Response format converted successfully", map[string]interface{}{
				"endpoint_type":  conversionContext.EndpointType,
				"original_size":  len(decompressedBody),
				"converted_size": len(convertedResp),
			})
		}
	}

	// åº”ç”¨å“åº”æ¨¡å‹é‡å†™ï¼ˆå¦‚æœè¿›è¡Œäº†è¯·æ±‚æ¨¡å‹é‡å†™ï¼‰
	finalResponseBody := convertedResponseBody
	if originalModel != "" && rewrittenModel != "" {
		rewrittenResponseBody, err := s.modelRewriter.RewriteResponse(convertedResponseBody, originalModel, rewrittenModel)
		if err != nil {
			s.logger.Error("Failed to rewrite response model", err)
			// å¦‚æœå“åº”é‡å†™å¤±è´¥ï¼Œä½¿ç”¨è½¬æ¢åçš„å“åº”ä½“ï¼Œä¸ä¸­æ–­è¯·æ±‚
		} else if len(rewrittenResponseBody) > 0 && !bytes.Equal(rewrittenResponseBody, convertedResponseBody) {
			// å¦‚æœå“åº”é‡å†™æˆåŠŸä¸”å†…å®¹å‘ç”Ÿäº†å˜åŒ–ï¼Œå‘é€é‡å†™åçš„æœªå‹ç¼©å“åº”
			// å¹¶ç§»é™¤Content-Encodingå¤´ï¼ˆå› ä¸ºæˆ‘ä»¬å‘é€çš„æ˜¯æœªå‹ç¼©æ•°æ®ï¼‰
			c.Header("Content-Encoding", "")
			c.Header("Content-Length", fmt.Sprintf("%d", len(rewrittenResponseBody)))
			finalResponseBody = rewrittenResponseBody
		} else {
			// å¦‚æœæ²¡æœ‰é‡å†™æˆ–é‡å†™åå†…å®¹æ²¡å˜åŒ–ï¼Œä½¿ç”¨è½¬æ¢åçš„å“åº”ä½“
			finalResponseBody = convertedResponseBody
		}
	} else if conversionContext != nil {
		// åªæœ‰æ ¼å¼è½¬æ¢æ²¡æœ‰æ¨¡å‹é‡å†™çš„æƒ…å†µ
		finalResponseBody = convertedResponseBody
	}

	// è®¾ç½®æ­£ç¡®çš„å“åº”å¤´éƒ¨
	if conversionContext != nil || (originalModel != "" && rewrittenModel != "") {
		// å¦‚æœè¿›è¡Œäº†è½¬æ¢æˆ–æ¨¡å‹é‡å†™ï¼Œéœ€è¦é‡æ–°è®¾ç½®å¤´éƒ¨
		// ç§»é™¤å‹ç¼©ç¼–ç ï¼ˆå› ä¸ºæˆ‘ä»¬å‘é€çš„æ˜¯è§£å‹åçš„æ•°æ®ï¼‰
		c.Header("Content-Encoding", "")
		// è®¾ç½®æ­£ç¡®çš„å†…å®¹é•¿åº¦
		c.Header("Content-Length", fmt.Sprintf("%d", len(finalResponseBody)))
	}

	// å¦‚æœæ˜¯æµå¼å“åº”ï¼Œç¡®ä¿è®¾ç½®æ­£ç¡®çš„SSEå¤´éƒ¨
	if isStreaming {
		c.Header("Content-Type", "text/event-stream; charset=utf-8")
		c.Header("Cache-Control", "no-cache")
		c.Header("Connection", "keep-alive")
		c.Header("X-Accel-Buffering", "no") // é˜²æ­¢ä¸­é—´å±‚ç¼“å†²
		// ç§»é™¤Content-Lengthå¤´éƒ¨ï¼ˆSSEä¸åº”è¯¥è®¾ç½®è¿™ä¸ªï¼‰
		c.Header("Content-Length", "")

		// Codex /responses API æ ¼å¼è½¬æ¢
		// Codex å®¢æˆ·ç«¯æœŸæœ› Responses API çš„ SSE äº‹ä»¶æ ¼å¼ï¼ˆtype: response.created/response.output_text.delta/response.completedï¼‰
		// è€Œä¸æ˜¯ Chat Completions çš„æ ¼å¼ï¼ˆobject: chat.completion.chunkï¼‰
		formatDetection, _ := c.Get("format_detection")
		isCodexClient := false
		if fd, ok := formatDetection.(*utils.FormatDetectionResult); ok {
			isCodexClient = (fd.ClientType == utils.ClientCodex)
		}

		if ep.EndpointType == "openai" && isCodexClient {
			s.logger.Info("Converting chat completions SSE to Responses API format for Codex", map[string]interface{}{
				"endpoint_type": ep.EndpointType,
				"client_type":   "codex",
				"path":          path,
			})
			finalResponseBody = s.convertChatCompletionsToResponsesSSE(finalResponseBody)
		}
	}

	// å‘é€æœ€ç»ˆå“åº”ä½“ç»™å®¢æˆ·ç«¯
	c.Writer.Write(finalResponseBody)

	// æ¸…é™¤é”™è¯¯ä¿¡æ¯ï¼ˆæˆåŠŸæƒ…å†µï¼‰
	c.Set("last_error", nil)
	c.Set("last_status_code", resp.StatusCode)

	duration := time.Since(endpointStartTime)
	// åˆ›å»ºæ—¥å¿—æ¡ç›®ï¼Œè®°å½•ä¿®æ”¹å‰åçš„å®Œæ•´æ•°æ®
	requestLog := s.logger.CreateRequestLog(requestID, ep.URL, c.Request.Method, path)
	requestLog.RequestBodySize = len(requestBody)
	requestLog.Tags = tags
	requestLog.ContentTypeOverride = overrideInfo
	requestLog.AttemptNumber = attemptNumber

	// è®¾ç½® thinking ä¿¡æ¯
	if thinkingInfo, exists := c.Get("thinking_info"); exists {
		if info, ok := thinkingInfo.(*utils.ThinkingInfo); ok && info != nil {
			requestLog.ThinkingEnabled = info.Enabled
			requestLog.ThinkingBudgetTokens = info.BudgetTokens
		}
	}

	// è®¾ç½®æ ¼å¼æ£€æµ‹ä¿¡æ¯
	if formatDetection, exists := c.Get("format_detection"); exists {
		if detection, ok := formatDetection.(*utils.FormatDetectionResult); ok && detection != nil {
			requestLog.ClientType = string(detection.ClientType)
			requestLog.RequestFormat = string(detection.Format)
			requestLog.TargetFormat = ep.EndpointType
			requestLog.FormatConverted = (conversionContext != nil)
			requestLog.DetectionConfidence = detection.Confidence
			requestLog.DetectedBy = detection.DetectedBy
		}
	}

	// è®°å½•åŸå§‹å®¢æˆ·ç«¯è¯·æ±‚æ•°æ®
	requestLog.OriginalRequestURL = c.Request.URL.String()
	requestLog.OriginalRequestHeaders = utils.HeadersToMap(c.Request.Header)
	if len(requestBody) > 0 {
		if s.config.Logging.LogRequestBody != "none" {
			if s.config.Logging.LogRequestBody == "truncated" {
				requestLog.OriginalRequestBody = utils.TruncateBody(string(requestBody), 1024)
			} else {
				requestLog.OriginalRequestBody = string(requestBody)
			}
		}
	}

	// è®°å½•æœ€ç»ˆå‘é€ç»™ä¸Šæ¸¸çš„è¯·æ±‚æ•°æ®
	requestLog.FinalRequestURL = req.URL.String()
	requestLog.FinalRequestHeaders = utils.HeadersToMap(req.Header)
	if len(finalRequestBody) > 0 {
		if s.config.Logging.LogRequestBody != "none" {
			if s.config.Logging.LogRequestBody == "truncated" {
				requestLog.FinalRequestBody = utils.TruncateBody(string(finalRequestBody), 1024)
			} else {
				requestLog.FinalRequestBody = string(finalRequestBody)
			}
		}
	}

	// è®°å½•ä¸Šæ¸¸åŸå§‹å“åº”æ•°æ®
	requestLog.OriginalResponseHeaders = utils.HeadersToMap(resp.Header)
	if len(decompressedBody) > 0 {
		if s.config.Logging.LogResponseBody != "none" {
			if s.config.Logging.LogResponseBody == "truncated" {
				requestLog.OriginalResponseBody = utils.TruncateBody(string(decompressedBody), 1024)
			} else {
				requestLog.OriginalResponseBody = string(decompressedBody)
			}
		}
	}

	// è®°å½•æœ€ç»ˆå‘é€ç»™å®¢æˆ·ç«¯çš„å“åº”æ•°æ®
	finalHeaders := make(map[string]string)
	for key := range resp.Header {
		values := c.Writer.Header().Values(key)
		if len(values) > 0 {
			finalHeaders[key] = values[0]
		}
	}
	requestLog.FinalResponseHeaders = finalHeaders
	if len(finalResponseBody) > 0 {
		if s.config.Logging.LogResponseBody != "none" {
			if s.config.Logging.LogResponseBody == "truncated" {
				requestLog.FinalResponseBody = utils.TruncateBody(string(finalResponseBody), 1024)
			} else {
				requestLog.FinalResponseBody = string(finalResponseBody)
			}
		}
	}

	// åŠ¨æ€APIæ ¼å¼å­¦ä¹  - æ ¹æ®æˆåŠŸå“åº”æ›´æ–°ç«¯ç‚¹æ ¼å¼åå¥½
	if formatDetection != nil && formatDetection.ClientType == utils.ClientCodex && ep.EndpointType == "openai" {
		// åªæœ‰å½“ /responses è·¯å¾„æˆåŠŸæ—¶ï¼Œæ‰æ ‡è®°ç«¯ç‚¹æ”¯æŒåŸç”Ÿ Codex æ ¼å¼
		// /chat/completions æˆåŠŸä¸ä»£è¡¨æ”¯æŒ /responses
		if inboundPath == "/responses" {
			s.updateEndpointCodexSupport(ep, true)
		}
	} else if formatDetection != nil && formatDetection.ClientType == utils.ClientClaudeCode && ep.EndpointType == "anthropic" {
		// æ£€æµ‹åˆ°Claude Codeè¯·æ±‚æˆåŠŸé€šè¿‡Anthropicç«¯ç‚¹ï¼Œç¡®è®¤ç«¯ç‚¹æ”¯æŒ
		s.updateEndpointCodexSupport(ep, false)
	}

	// è®¾ç½®å…¼å®¹æ€§å­—æ®µ
	requestLog.RequestHeaders = requestLog.FinalRequestHeaders
	requestLog.RequestBody = requestLog.OriginalRequestBody
	requestLog.ResponseHeaders = requestLog.OriginalResponseHeaders
	requestLog.ResponseBody = requestLog.OriginalResponseBody

	// è®¾ç½®æ¨¡å‹ä¿¡æ¯
	if len(requestBody) > 0 {
		extractedModel := utils.ExtractModelFromRequestBody(string(requestBody))
		if originalModel != "" {
			requestLog.Model = originalModel
			requestLog.OriginalModel = originalModel
		} else {
			requestLog.Model = extractedModel
			requestLog.OriginalModel = extractedModel
		}

		if rewrittenModel != "" {
			requestLog.RewrittenModel = rewrittenModel
			requestLog.ModelRewriteApplied = rewrittenModel != requestLog.OriginalModel
		}

		// æå– Session ID
		requestLog.SessionID = utils.ExtractSessionIDFromRequestBody(string(requestBody))
	}

	// æ›´æ–°åŸºæœ¬å­—æ®µ
	s.logger.UpdateRequestLog(requestLog, req, resp, decompressedBody, duration, nil)
	requestLog.IsStreaming = isStreaming
	s.logger.LogRequest(requestLog)

        // ğŸ” è‡ªåŠ¨æ¢æµ‹æˆåŠŸï¼šå¦‚æœæ˜¯é¦–æ¬¡ /responses è¯·æ±‚ä¸”æˆåŠŸï¼Œæ ‡è®°ä¸ºæ”¯æŒåŸç”Ÿ Codex æ ¼å¼
        if ep.EndpointType == "openai" && inboundPath == "/responses" && ep.NativeCodexFormat == nil {
            trueValue := true
            ep.NativeCodexFormat = &trueValue
            s.logger.Info("Auto-detected: endpoint natively supports Codex format", map[string]interface{}{
                "endpoint": ep.Name,
            })
        }

	return true, false
}

// applyParameterOverrides åº”ç”¨è¯·æ±‚å‚æ•°è¦†ç›–è§„åˆ™
// autoRemoveUnsupportedParams åŸºäºç«¯ç‚¹å­¦ä¹ åˆ°çš„ä¿¡æ¯è‡ªåŠ¨ç§»é™¤ä¸æ”¯æŒçš„å‚æ•°
func (s *Server) autoRemoveUnsupportedParams(requestBody []byte, ep *endpoint.Endpoint) ([]byte, bool) {
	// è·å–ç«¯ç‚¹å­¦ä¹ åˆ°çš„ä¸æ”¯æŒå‚æ•°åˆ—è¡¨
	unsupportedParams := ep.GetLearnedUnsupportedParams()
	if len(unsupportedParams) == 0 {
		return requestBody, false
	}

	// è§£æè¯·æ±‚ä½“
	var requestData map[string]interface{}
	if err := json.Unmarshal(requestBody, &requestData); err != nil {
		return requestBody, false
	}

	// ç§»é™¤å­¦ä¹ åˆ°çš„ä¸æ”¯æŒå‚æ•°
	modified := false
	for _, param := range unsupportedParams {
		if _, exists := requestData[param]; exists {
			delete(requestData, param)
			modified = true
			s.logger.Debug(fmt.Sprintf("Auto-removed '%s' parameter (learned from previous failures)", param))
		}
	}

	if !modified {
		return requestBody, false
	}

	// é‡æ–°åºåˆ—åŒ–
	modifiedBody, err := json.Marshal(requestData)
	if err != nil {
		return requestBody, false
	}

	return modifiedBody, true
}

func (s *Server) applyParameterOverrides(requestBody []byte, parameterOverrides map[string]string) ([]byte, error) {
	if len(parameterOverrides) == 0 {
		return requestBody, nil
	}

	// è§£æJSONè¯·æ±‚ä½“
	var requestData map[string]interface{}
	if err := json.Unmarshal(requestBody, &requestData); err != nil {
		// å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ä¸è¿”å›é”™è¯¯ï¼Œä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
		s.logger.Debug("Failed to parse request body as JSON for parameter override, using original body", map[string]interface{}{
			"error": err.Error(),
		})
		return requestBody, nil
	}

	// åº”ç”¨å‚æ•°è¦†ç›–è§„åˆ™
	modified := false
	for paramName, paramValue := range parameterOverrides {
		if paramValue == "" {
			// ç©ºå€¼è¡¨ç¤ºåˆ é™¤å‚æ•°
			if _, exists := requestData[paramName]; exists {
				delete(requestData, paramName)
				modified = true
				s.logger.Debug(fmt.Sprintf("Parameter override: deleted parameter %s", paramName))
			}
		} else {
			// éç©ºå€¼è¡¨ç¤ºè®¾ç½®å‚æ•°
			// å°è¯•è§£æå‚æ•°å€¼ä¸ºé€‚å½“çš„ç±»å‹
			var parsedValue interface{}
			if err := json.Unmarshal([]byte(paramValue), &parsedValue); err != nil {
				// å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½œä¸ºå­—ç¬¦ä¸²å¤„ç†
				parsedValue = paramValue
			}
			requestData[paramName] = parsedValue
			modified = true
			s.logger.Debug(fmt.Sprintf("Parameter override: set parameter %s = %v", paramName, parsedValue))
		}
	}

	// å¦‚æœæ²¡æœ‰ä¿®æ”¹ï¼Œè¿”å›åŸå§‹è¯·æ±‚ä½“
	if !modified {
		return requestBody, nil
	}

	// é‡æ–°åºåˆ—åŒ–ä¸ºJSON
	modifiedBody, err := json.Marshal(requestData)
	if err != nil {
		s.logger.Error("Failed to marshal modified request body", err)
		return requestBody, nil // è¿”å›åŸå§‹è¯·æ±‚ä½“
	}

	return modifiedBody, nil
}

// applyOpenAIUserLengthHack åº”ç”¨ OpenAI user å‚æ•°é•¿åº¦é™åˆ¶ hack
func (s *Server) applyOpenAIUserLengthHack(requestBody []byte) ([]byte, error) {
	// è§£æJSONè¯·æ±‚ä½“
	var requestData map[string]interface{}
	if err := json.Unmarshal(requestBody, &requestData); err != nil {
		// å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ä¸è¿”å›é”™è¯¯ï¼Œä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
		s.logger.Debug("Failed to parse request body as JSON for OpenAI user hack, using original body", map[string]interface{}{
			"error": err.Error(),
		})
		return nil, nil
	}

	// æ£€æŸ¥æ˜¯å¦å­˜åœ¨ user å‚æ•°
	userValue, exists := requestData["user"]
	if !exists {
		return nil, nil // æ²¡æœ‰ user å‚æ•°ï¼Œæ— éœ€å¤„ç†
	}

	// è½¬æ¢ä¸ºå­—ç¬¦ä¸²
	userStr, ok := userValue.(string)
	if !ok {
		return nil, nil // user å‚æ•°ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œæ— éœ€å¤„ç†
	}

	// æ£€æŸ¥é•¿åº¦ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰
	if len(userStr) <= 64 {
		return nil, nil // é•¿åº¦åœ¨é™åˆ¶å†…ï¼Œæ— éœ€å¤„ç†
	}

	// ç”Ÿæˆ hash
	hasher := md5.New()
	hasher.Write([]byte(userStr))
	hashBytes := hasher.Sum(nil)
	hashStr := hex.EncodeToString(hashBytes)

	// æ·»åŠ å‰ç¼€æ ‡è¯†
	hashedUser := "hashed-" + hashStr

	// æ›´æ–°è¯·æ±‚æ•°æ®
	requestData["user"] = hashedUser

	s.logger.Info("OpenAI user parameter hashed due to length limit", map[string]interface{}{
		"original_length": len(userStr),
		"hashed_length":   len(hashedUser),
		"original_user":   userStr[:min(32, len(userStr))] + "...", // åªè®°å½•å‰32ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
	})

	// é‡æ–°åºåˆ—åŒ–ä¸ºJSON
	modifiedBody, err := json.Marshal(requestData)
	if err != nil {
		s.logger.Error("Failed to marshal request body after user hash", err)
		return nil, err
	}

	return modifiedBody, nil
}

// applyGPT5ModelHack åº”ç”¨ GPT-5 æ¨¡å‹ç‰¹æ®Šå¤„ç† hack
// å¦‚æœæ¨¡å‹ååŒ…å« "gpt5" ä¸”ç«¯ç‚¹æ˜¯ OpenAI ç±»å‹ï¼Œåˆ™ï¼š
// 1. å¦‚æœ temperature ä¸æ˜¯ 1 åˆ™å°†å…¶æ”¹ä¸º 1
// 2. å¦‚æœåŒ…å« max_tokens å­—æ®µï¼Œåˆ™å°†å…¶æ”¹åä¸º max_completion_tokens
func (s *Server) applyGPT5ModelHack(requestBody []byte) ([]byte, error) {
	// è§£æJSONè¯·æ±‚ä½“
	var requestData map[string]interface{}
	if err := json.Unmarshal(requestBody, &requestData); err != nil {
		// å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ä¸è¿”å›é”™è¯¯ï¼Œä½¿ç”¨åŸå§‹è¯·æ±‚ä½“
		s.logger.Debug("Failed to parse request body as JSON for GPT-5 hack, using original body", map[string]interface{}{
			"error": err.Error(),
		})
		return nil, nil
	}

	// æ£€æŸ¥æ˜¯å¦ä¸º GPT-5 æ¨¡å‹
	modelValue, exists := requestData["model"]
	if !exists {
		return nil, nil // æ²¡æœ‰ model å‚æ•°ï¼Œæ— éœ€å¤„ç†
	}

	modelStr, ok := modelValue.(string)
	if !ok {
		return nil, nil // model å‚æ•°ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œæ— éœ€å¤„ç†
	}

	// æ£€æŸ¥æ¨¡å‹åæ˜¯å¦åŒ…å« "gpt-5"ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
	if !strings.Contains(strings.ToLower(modelStr), "gpt-5") {
		return nil, nil // ä¸æ˜¯ GPT-5 æ¨¡å‹ï¼Œæ— éœ€å¤„ç†
	}

	modified := false
	var hackDetails []string

	// 1. æ£€æŸ¥å¹¶ä¿®æ”¹ temperature
	if tempValue, exists := requestData["temperature"]; exists {
		if temp, ok := tempValue.(float64); ok && temp != 1.0 {
			requestData["temperature"] = 1.0
			modified = true
			hackDetails = append(hackDetails, fmt.Sprintf("temperature: %.3f â†’ 1.0", temp))
		}
	} else {
		// å¦‚æœæ²¡æœ‰ temperatureï¼Œè®¾ç½®ä¸º 1.0
		requestData["temperature"] = 1.0
		modified = true
		hackDetails = append(hackDetails, "temperature: not set â†’ 1.0")
	}

	// 2. æ£€æŸ¥å¹¶é‡å‘½å max_tokens ä¸º max_completion_tokens
	if maxTokensValue, exists := requestData["max_tokens"]; exists {
		// å°† max_tokens æ”¹åä¸º max_completion_tokens
		requestData["max_completion_tokens"] = maxTokensValue
		delete(requestData, "max_tokens")
		modified = true
		hackDetails = append(hackDetails, fmt.Sprintf("max_tokens â†’ max_completion_tokens: %v", maxTokensValue))
	}

	// å¦‚æœæ²¡æœ‰ä¿®æ”¹ï¼Œè¿”å› nil
	if !modified {
		return nil, nil
	}

	s.logger.Info("GPT-5 model hack applied", map[string]interface{}{
		"model":   modelStr,
		"changes": hackDetails,
	})

	// é‡æ–°åºåˆ—åŒ–ä¸ºJSON
	modifiedBody, err := json.Marshal(requestData)
	if err != nil {
		s.logger.Error("Failed to marshal request body after GPT-5 hack", err)
		return nil, err
	}

	return modifiedBody, nil
}

// min è¿”å›ä¸¤ä¸ªæ•´æ•°ä¸­çš„è¾ƒå°å€¼
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// processRateLimitHeaders å¤„ç†Anthropic rate limit headers
func (s *Server) processRateLimitHeaders(ep *endpoint.Endpoint, headers http.Header, requestID string) error {
	resetHeader := headers.Get("Anthropic-Ratelimit-Unified-Reset")
	statusHeader := headers.Get("Anthropic-Ratelimit-Unified-Status")

	// è½¬æ¢resetä¸ºint64
	var resetValue *int64
	if resetHeader != "" {
		if parsed, err := strconv.ParseInt(resetHeader, 10, 64); err == nil {
			resetValue = &parsed
		} else {
			s.logger.Debug("Failed to parse Anthropic-Ratelimit-Unified-Reset header", map[string]interface{}{
				"value":      resetHeader,
				"error":      err.Error(),
				"endpoint":   ep.Name,
				"request_id": requestID,
			})
		}
	}

	var statusValue *string
	if statusHeader != "" {
		statusValue = &statusHeader
	}

	// æ›´æ–°endpointçŠ¶æ€
	changed, err := ep.UpdateRateLimitState(resetValue, statusValue)
	if err != nil {
		return err
	}

	// å¦‚æœçŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼ŒæŒä¹…åŒ–åˆ°é…ç½®æ–‡ä»¶
	if changed {
		s.logger.Info("Rate limit state changed, persisting to config", map[string]interface{}{
			"endpoint":   ep.Name,
			"reset":      resetValue,
			"status":     statusValue,
			"request_id": requestID,
		})

		// æŒä¹…åŒ–åˆ°é…ç½®æ–‡ä»¶
		if err := s.persistRateLimitState(ep.ID, resetValue, statusValue); err != nil {
			s.logger.Error("Failed to persist rate limit state", err)
			return err
		}
	}

	// æ£€æŸ¥å¢å¼ºä¿æŠ¤ï¼šå¦‚æœå¯ç”¨äº†å¢å¼ºä¿æŠ¤ä¸”çŠ¶æ€ä¸ºallowed_warningï¼Œåˆ™ç¦ç”¨ç«¯ç‚¹
	if ep.ShouldDisableOnAllowedWarning() && ep.IsAvailable() {
		s.logger.Info("Enhanced protection triggered: disabling endpoint due to allowed_warning status", map[string]interface{}{
			"endpoint":            ep.Name,
			"status":              statusValue,
			"enhanced_protection": true,
			"request_id":          requestID,
		})
		ep.MarkInactive()
	}

	return nil
}

// convertChatCompletionsToResponsesSSE å°† OpenAI /chat/completions SSE æ ¼å¼è½¬æ¢ä¸º /responses API æ ¼å¼
// Codex å®¢æˆ·ç«¯ä½¿ç”¨ /responses APIï¼ŒæœŸæœ›çš„äº‹ä»¶æ ¼å¼ä¸ºï¼š
//   - {"type": "response.created", "response": {...}}
//   - {"type": "response.output_text.delta", "delta": "..."}
//   - {"type": "response.completed", "response": {...}}
func (s *Server) convertChatCompletionsToResponsesSSE(body []byte) []byte {
	bodyStr := string(body)
	lines := strings.Split(bodyStr, "\n")

	var convertedLines []string
	responseID := ""
	model := ""
	created := int64(0)
	hasStarted := false

	for _, line := range lines {
		// SSE æ ¼å¼ï¼šdata: {...}
		if !strings.HasPrefix(line, "data: ") {
			convertedLines = append(convertedLines, line)
			continue
		}

		dataStr := strings.TrimPrefix(line, "data: ")
		dataStr = strings.TrimSpace(dataStr)

		// è·³è¿‡ [DONE] æ ‡è®°ï¼Œç¨åæ·»åŠ  response.completed
		if dataStr == "[DONE]" {
			continue
		}

		// è§£æ JSON
		var chunk map[string]interface{}
		if err := json.Unmarshal([]byte(dataStr), &chunk); err != nil {
			convertedLines = append(convertedLines, line)
			continue
		}

		// æå–åŸºæœ¬ä¿¡æ¯
		if id, ok := chunk["id"].(string); ok && responseID == "" {
			responseID = id
		}
		if m, ok := chunk["model"].(string); ok && model == "" {
			model = m
		}
		if c, ok := chunk["created"].(float64); ok && created == 0 {
			created = int64(c)
		}

		// è·å– choices æ•°ç»„
		choices, ok := chunk["choices"].([]interface{})
		if !ok || len(choices) == 0 {
			continue
		}

		choice := choices[0].(map[string]interface{})
		delta, hasDelta := choice["delta"].(map[string]interface{})
		finishReason, _ := choice["finish_reason"].(string)

		// ç¬¬ä¸€ä¸ªäº‹ä»¶ï¼šresponse.created
		if !hasStarted {
			hasStarted = true
			event := map[string]interface{}{
				"type": "response.created",
				"response": map[string]interface{}{
					"id":      responseID,
					"object":  "response",
					"created": created,
					"model":   model,
					"status":  "in_progress",
				},
			}
			eventJSON, _ := json.Marshal(event)
			convertedLines = append(convertedLines, "data: "+string(eventJSON))
			convertedLines = append(convertedLines, "")
		}

		// å†…å®¹å¢é‡äº‹ä»¶ï¼šresponse.output_text.delta
		if hasDelta {
			if role, hasRole := delta["role"]; hasRole && role != "" {
				// è§’è‰²å˜åŒ–ï¼Œå¿½ç•¥æˆ–å¤„ç†
				_ = role
			}

			if content, hasContent := delta["content"].(string); hasContent && content != "" {
				event := map[string]interface{}{
					"type":  "response.output_text.delta",
					"delta": content,
					"response_id": responseID,
				}
				eventJSON, _ := json.Marshal(event)
				convertedLines = append(convertedLines, "data: "+string(eventJSON))
				convertedLines = append(convertedLines, "")
			}
		}

		// ç»“æŸäº‹ä»¶ï¼šresponse.completed
		if finishReason != "" {
			event := map[string]interface{}{
				"type": "response.completed",
				"response": map[string]interface{}{
					"id":            responseID,
					"object":        "response",
					"created":       created,
					"model":         model,
					"status":        "completed",
					"finish_reason": finishReason,
				},
			}
			eventJSON, _ := json.Marshal(event)
			convertedLines = append(convertedLines, "data: "+string(eventJSON))
			convertedLines = append(convertedLines, "")
		}
	}

	result := strings.Join(convertedLines, "\n")

	s.logger.Debug("Converted chat completions SSE to Responses API format", map[string]interface{}{
		"original_size": len(body),
		"converted_size": len(result),
		"response_id": responseID,
	})

	return []byte(result)
}

// convertCodexToOpenAI å°† Codex /responses æ ¼å¼è½¬æ¢ä¸º OpenAI /chat/completions æ ¼å¼
// Codex æ ¼å¼å¤æ‚ï¼ŒåŒ…å«å¤šä¸ªç‰¹æ®Šå­—æ®µï¼š
//   - instructions: ç³»ç»Ÿæç¤ºï¼ˆå­—ç¬¦ä¸²ï¼‰
//   - input: æ¶ˆæ¯æ•°ç»„ï¼ˆç»“æ„ä¸ OpenAI messages ä¸åŒï¼‰
//   - include: å“åº”åŒ…å«é€‰é¡¹ï¼ˆCodex ç‰¹æœ‰ï¼‰
// è½¬æ¢ç­–ç•¥ï¼š
//   1. ä» input æ•°ç»„æå–å†…å®¹ï¼Œè½¬æ¢ä¸ºæ ‡å‡† OpenAI messages æ ¼å¼
//   2. instructions ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
//   3. åˆ é™¤ Codex ç‰¹æœ‰å­—æ®µï¼ˆinput, include ç­‰ï¼‰
func (s *Server) convertCodexToOpenAI(requestBody []byte) ([]byte, error) {
	// è§£æè¯·æ±‚ä½“
	var requestData map[string]interface{}
	if err := json.Unmarshal(requestBody, &requestData); err != nil {
		s.logger.Error("Failed to parse request body for Codex conversion", err)
		return nil, err
	}

	// æ£€æŸ¥æ˜¯å¦æ˜¯ Codex æ ¼å¼ï¼ˆè‡³å°‘è¦æœ‰ input æˆ– instructions å­—æ®µä¹‹ä¸€ï¼‰
	_, hasInput := requestData["input"]
	_, hasInstructions := requestData["instructions"]

	if !hasInput && !hasInstructions {
		// ä¸æ˜¯ Codex æ ¼å¼ï¼Œè·³è¿‡è½¬æ¢
		return nil, nil
	}

	// æ„å»º OpenAI messages æ•°ç»„
	messages := []map[string]interface{}{}

	// 1. å¤„ç† instructionsï¼ˆä½œä¸º system æ¶ˆæ¯ï¼‰
	if hasInstructions {
		if instructionsStr, ok := requestData["instructions"].(string); ok && instructionsStr != "" {
			messages = append(messages, map[string]interface{}{
				"role":    "system",
				"content": instructionsStr,
			})
		}
		delete(requestData, "instructions")
	}

	// 2. å¤„ç† input æ•°ç»„ï¼ˆè½¬æ¢ä¸º user/assistant æ¶ˆæ¯ï¼‰
	if hasInput {
		if inputArray, ok := requestData["input"].([]interface{}); ok {
			for _, item := range inputArray {
				if inputMsg, ok := item.(map[string]interface{}); ok {
					// æå– role
					role, _ := inputMsg["role"].(string)
					if role == "" {
						role = "user" // é»˜è®¤ä¸º user
					}

					// æå– content
					// Codex çš„ content æ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å« {text, type} å¯¹è±¡
					var contentStr string
					if contentArray, ok := inputMsg["content"].([]interface{}); ok {
						for _, contentItem := range contentArray {
							if contentObj, ok := contentItem.(map[string]interface{}); ok {
								if text, ok := contentObj["text"].(string); ok {
									contentStr += text
								}
							}
						}
					}

					if contentStr != "" {
						messages = append(messages, map[string]interface{}{
							"role":    role,
							"content": contentStr,
						})
					}
				}
			}
		}
		delete(requestData, "input")
	}

	// å¦‚æœæ²¡æœ‰æˆåŠŸè½¬æ¢å‡ºä»»ä½•æ¶ˆæ¯ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤çš„ user æ¶ˆæ¯
	if len(messages) == 0 {
		messages = append(messages, map[string]interface{}{
			"role":    "user",
			"content": "Hello",
		})
	}

	// è®¾ç½® messages å­—æ®µ
	requestData["messages"] = messages

	// åˆ é™¤å…¶ä»– Codex ç‰¹æœ‰å­—æ®µ
	delete(requestData, "include") // Codex ç‰¹æœ‰çš„å“åº”é€‰é¡¹
	
	// ä¿ç•™ä»¥ä¸‹å­—æ®µï¼ˆOpenAI å…¼å®¹ï¼‰ï¼š
	// - tools: å·¥å…·å®šä¹‰æ•°ç»„ï¼ˆOpenAI æ ‡å‡†ï¼‰
	// - tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥ï¼ˆOpenAI æ ‡å‡†ï¼‰
	// - stream: æµå¼å“åº”æ ‡å¿—ï¼ˆOpenAI æ ‡å‡†ï¼‰
	// - temperature, max_tokens ç­‰å‚æ•°ï¼ˆOpenAI æ ‡å‡†ï¼‰
	
	// æ³¨æ„ï¼štools å­—æ®µåœ¨ Codex å’Œ OpenAI ä¸­æ ¼å¼ç›¸åŒï¼Œå¯ä»¥ç›´æ¥ä¿ç•™
	// ä¸éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œåªéœ€ç¡®ä¿ä¸è¢«åˆ é™¤

	// é‡æ–°åºåˆ—åŒ–ä¸º JSON
	convertedBody, err := json.Marshal(requestData)
	if err != nil {
		s.logger.Error("Failed to marshal converted request body", err)
		return nil, err
	}
	
	s.logger.Debug("Codex to OpenAI conversion completed", map[string]interface{}{
		"messages_count": len(messages),
		"has_tools":      requestData["tools"] != nil,
		"has_stream":     requestData["stream"] != nil,
	})

	return convertedBody, nil
}

// åŠ¨æ€æ›´æ–°ç«¯ç‚¹çš„Codexæ”¯æŒçŠ¶æ€
func (s *Server) updateEndpointCodexSupport(ep *endpoint.Endpoint, isCodex bool) {
	if ep == nil {
		return
	}

	// ä½¿ç”¨ç«¯ç‚¹çš„å…¬å…±æ–¹æ³•æ¥å®‰å…¨åœ°æ›´æ–°çŠ¶æ€
	ep.UpdateNativeCodexSupport(isCodex)
	s.logger.Info(fmt.Sprintf("Updated endpoint %s native_codex_support to %v", ep.Name, isCodex))
}

// ğŸ“ ä»400é”™è¯¯å“åº”ä¸­å­¦ä¹ ä¸æ”¯æŒçš„å‚æ•°
func (s *Server) learnUnsupportedParamsFromError(errorBody []byte, ep *endpoint.Endpoint, requestBody []byte) {
	if ep == nil || len(errorBody) == 0 {
		return
	}

	// è§£æé”™è¯¯æ¶ˆæ¯
	var errorData map[string]interface{}
	if err := json.Unmarshal(errorBody, &errorData); err != nil {
		return // æ— æ³•è§£æä¸ºJSON,å¿½ç•¥
	}

	// å°è¯•ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–å‚æ•°å
	errorMsg := ""
	if msg, ok := errorData["message"].(string); ok {
		errorMsg = msg
	} else if err, ok := errorData["error"].(map[string]interface{}); ok {
		if msg, ok := err["message"].(string); ok {
			errorMsg = msg
		}
	} else if err, ok := errorData["error"].(string); ok {
		errorMsg = err
	}

	if errorMsg == "" {
		return
	}

	// è§£æè¯·æ±‚ä½“ä»¥æ£€æŸ¥å“ªäº›å‚æ•°å­˜åœ¨
	var requestData map[string]interface{}
	if err := json.Unmarshal(requestBody, &requestData); err != nil {
		return
	}

	// å¸¸è§çš„ä¸æ”¯æŒå‚æ•°å…³é”®è¯æ¨¡å¼
	unsupportedPatterns := []struct {
		keywords []string
		params   []string
	}{
		{
			keywords: []string{"tool", "function", "function_call", "tool_choice"},
			params:   []string{"tools", "tool_choice", "functions", "function_call"},
		},
		{
			keywords: []string{"unsupported", "not supported", "invalid parameter", "unexpected parameter"},
			params:   []string{}, // å°†ä»é”™è¯¯æ¶ˆæ¯ä¸­åŠ¨æ€æå–
		},
	}

	errorMsgLower := strings.ToLower(errorMsg)

	// æ£€æŸ¥æ¯ä¸ªæ¨¡å¼
	for _, pattern := range unsupportedPatterns {
		matched := false
		for _, keyword := range pattern.keywords {
			if strings.Contains(errorMsgLower, keyword) {
				matched = true
				break
			}
		}

		if matched {
			// å¦‚æœæ¨¡å¼åŒ¹é…ï¼Œå­¦ä¹ å¯¹åº”çš„å‚æ•°
			if len(pattern.params) > 0 {
				for _, param := range pattern.params {
					if _, exists := requestData[param]; exists {
						ep.LearnUnsupportedParam(param)
						s.logger.Info("Learned unsupported parameter from API error", map[string]interface{}{
							"endpoint":  ep.Name,
							"parameter": param,
							"error_msg": errorMsg,
						})
					}
				}
			} else {
				// å°è¯•ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–å‚æ•°å
				// åŒ¹é…ç±»ä¼¼ "parameter 'xxx' is not supported" æˆ– "unsupported parameter: xxx"
				paramNameRegex := regexp.MustCompile(`parameter[\s'":]*([a-zA-Z_][a-zA-Z0-9_]*)`)
				matches := paramNameRegex.FindStringSubmatch(errorMsg)
				if len(matches) > 1 {
					paramName := matches[1]
					if _, exists := requestData[paramName]; exists {
						ep.LearnUnsupportedParam(paramName)
						s.logger.Info("Learned unsupported parameter from API error (regex)", map[string]interface{}{
							"endpoint":  ep.Name,
							"parameter": paramName,
							"error_msg": errorMsg,
						})
					}
				}
			}
		}
	}
}
